{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugixb2FtDw9M"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| ![gym](https://github.com/nadiinchi/dl_labs/blob/master/images/gym.png?raw=1) | ![img](https://github.com/nadiinchi/dl_labs/blob/master/images/pytorch.png?raw=1) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cg6xuMm-Dw9P"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install gym pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRZeB_EPDw9S"
      },
      "source": [
        "Agent interacts with the environment through actions (**A**), changing its state (**S**) and getting the reward (**R**).\n",
        "\n",
        "The final goal is to maximize a total reward.\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/recap.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUzG6P3kDw9R"
      },
      "source": [
        "# Reinforcement Learning Recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIETtGs7Dw9S"
      },
      "source": [
        "## Cart-Pole\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/cartpole.png?raw=1)\n",
        "\n",
        "* **Task** - keep the pole vertical as long as possible\n",
        "* **State** - angle, rotation speed, position, velocity\n",
        "* **Action** - horizontal force, applied to the cart\n",
        "* **Reward** - 1 for each moment with almost-vertical pole (e.g., 85-95 degrees)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FviqdWkkDw9S"
      },
      "source": [
        "## Atari\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/atari.png?raw=1)\n",
        "\n",
        "* **Task** - get as many points as possible\n",
        "* **State** - game screen (screenshots)\n",
        "* **Action** - various buttons\n",
        "* **Reward** - is defined by a particular game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s01YW65Dw9T"
      },
      "source": [
        "## Doom\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/doom.png?raw=1)\n",
        "\n",
        "* **Target** - kill 'em all\n",
        "* **State** - game screen (screenshots)\n",
        "* **Action** - various buttons\n",
        "* **Reward** - +1 for killing an enemy, -N for dying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1ElZlN7Dw9T"
      },
      "source": [
        "## Discounted reward\n",
        "\n",
        "It is common to use a discount factor $\\gamma$ to give higher weights for closer rewards.\n",
        "\n",
        "Without the dicounted factor a total reward for all the states after $t$ can be defined as\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/nodiscount.png?raw=1)\n",
        "\n",
        "With the discounted factor we focus on the current rewards as the state can change in the future:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/discount.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s53pPf7mDw9T"
      },
      "source": [
        "## Value function\n",
        "\n",
        "We want to know how good (valuable) each state is. It would help us to choose the best state to go.\n",
        "\n",
        "The value function represent how good is a state for an agent to be in. It is equal to expected total reward for an agent starting from state s. The value function depends on the policy by which the agent picks actions to perform. So, if the agent uses a given policy $\\pi$ to select actions, the corresponding value function is given by\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/vpolicy.png?raw=1)\n",
        "\n",
        "Among all possible value-functions, there exist an **optimal value function** that has higher value than other functions for all states:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/voptimal.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSwnQ6nHDw9T"
      },
      "source": [
        "## Q-function\n",
        "\n",
        "Even having optimal value functions we can't just choose the best state, only to choose an action `a`.\n",
        "\n",
        "For better actions choice there is a quality-function Q defining the effectiveness of such actions.\n",
        "\n",
        "$Q^\\pi(s, a)$ is defined as an expected reward for making action `a` and following $\\pi$ afterwards.\n",
        "\n",
        "Just like with the value function, there is an optimal $Q^*(s, a)$\n",
        "\n",
        "Since $V^*(s)$ is the maximum expected total reward when starting from state `s`, it will be the maximum of $Q^*(s, a)$ over all possible actions. Therefore, the relationship between $Q^*(s, a)$ and $V^*(s)$ is easily obtained as:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/VQ.png?raw=1)\n",
        "\n",
        "The optimal strategy is therefore derived from the optimal $Q$:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/pioptimal.png?raw=1)\n",
        "\n",
        "As the result **the task** of optimal strategy search for an agent **is** reduced to **defining $V^*$ Ð¸ $Q^*$**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBO-Yt_wDw9U"
      },
      "source": [
        "## Q-learning\n",
        "\n",
        "$Q(s, a)$ is defined recursevly through the Bellman equation as\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/bellman.png?raw=1)\n",
        "\n",
        "The Q-learning idea is to estimate Q iteratively w.r.t. the Bellman equation:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/qiter.png?raw=1)\n",
        "\n",
        "The initial approximations will be random but the more the agent knows the closer we are to $Q^*$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKayt6geDw9U"
      },
      "source": [
        "# \"Handmade\" environment\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/zombie.png?raw=1)\n",
        "\n",
        "We want to find an icecream and not to be eaten by zombie at the same time.\n",
        "\n",
        "Our action is chosen from 4 directions to go from the current cell.\n",
        "\n",
        "Initial state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3QXsAdgDw9V",
        "outputId": "c612e07c-f4fb-41b1-e8f8-c45e336fe5bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i *\n",
            "z c\n"
          ]
        }
      ],
      "source": [
        "ZOMBIE = \"z\"\n",
        "CAR = \"c\"\n",
        "ICE_CREAM = \"i\"\n",
        "EMPTY = \"*\"\n",
        "\n",
        "grid = [\n",
        "    [ICE_CREAM, EMPTY],\n",
        "    [ZOMBIE, CAR]\n",
        "]\n",
        "\n",
        "for row in grid:\n",
        "    print(' '.join(row))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq-vH80jDw9X"
      },
      "source": [
        "State class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "58jxQuP6Dw9X"
      },
      "outputs": [],
      "source": [
        "class State:\n",
        "    def __init__(self, grid, car_pos):\n",
        "        self.grid = grid\n",
        "        self.car_pos = car_pos\n",
        "        \n",
        "    def __eq__(self, other):\n",
        "        return isinstance(other, State) and self.grid == other.grid and self.car_pos == other.car_pos\n",
        "    \n",
        "    def __hash__(self):\n",
        "        return hash(str(self.grid) + str(self.car_pos))\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"State(grid={self.grid}, car_pos={self.car_pos})\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQAYJRRSDw9X"
      },
      "source": [
        "Actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQqJahc0Dw9X"
      },
      "outputs": [],
      "source": [
        "UP = 0\n",
        "DOWN = 1\n",
        "LEFT = 2\n",
        "RIGHT = 3\n",
        "\n",
        "ACTIONS = [UP, DOWN, LEFT, RIGHT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHlGqHK2Dw9X"
      },
      "source": [
        "Initial state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRWFzireDw9Y",
        "outputId": "82f54865-f727-4ec6-b201-452f50af9ecc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_state = State(grid=grid, car_pos=[1, 1])\n",
        "start_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsQQUVJkDw9Y"
      },
      "source": [
        "Action functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YOtkP0-ADw9Y"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def act(state, action):\n",
        "    def new_car_pos(state, action):\n",
        "        p = deepcopy(state.car_pos)\n",
        "        if action == UP:\n",
        "            p[0] = max(0, p[0] - 1)\n",
        "        elif action == DOWN:\n",
        "            p[0] = min(len(state.grid) - 1, p[0] + 1)\n",
        "        elif action == LEFT:\n",
        "            p[1] = max(0, p[1] - 1)\n",
        "        elif action == RIGHT:\n",
        "            p[1] = min(len(state.grid[0]) - 1, p[1] + 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown action {action}\")\n",
        "        return p\n",
        "\n",
        "    p = new_car_pos(state, action)\n",
        "    grid_item = state.grid[p[0]][p[1]]\n",
        "    \n",
        "    new_grid = deepcopy(state.grid)\n",
        "    \n",
        "    if grid_item == ZOMBIE:\n",
        "        reward = -100\n",
        "        is_done = True\n",
        "        new_grid[p[0]][p[1]] += CAR\n",
        "    elif grid_item == ICE_CREAM:\n",
        "        reward = 1000\n",
        "        is_done = True\n",
        "        new_grid[p[0]][p[1]] += CAR\n",
        "    elif grid_item == EMPTY:\n",
        "        reward = -1\n",
        "        is_done = False\n",
        "        old = state.car_pos\n",
        "        new_grid[old[0]][old[1]] = EMPTY\n",
        "        new_grid[p[0]][p[1]] = CAR\n",
        "    elif grid_item == CAR:\n",
        "        reward = -1\n",
        "        is_done = False\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown grid item {grid_item}\")\n",
        "\n",
        "    return State(grid=new_grid, car_pos=p), reward, is_done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8NxgC6XDw9Y"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7UqGybjuDw9Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "N_STATES = 4\n",
        "N_EPISODES = 20\n",
        "\n",
        "MAX_EPISODE_STEPS = 100\n",
        "\n",
        "MIN_ALPHA = 0.02\n",
        "\n",
        "alphas = np.linspace(1.0, MIN_ALPHA, N_EPISODES)\n",
        "gamma = 1.0\n",
        "eps = 0.2\n",
        "\n",
        "q_table = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RNjLdm0bDw9Z"
      },
      "outputs": [],
      "source": [
        "def q(state, action=None):\n",
        "    if state not in q_table:\n",
        "        q_table[state] = np.zeros(len(ACTIONS))\n",
        "\n",
        "    if action is None:\n",
        "        return q_table[state]\n",
        "\n",
        "    return q_table[state][action]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "plk_MayUDw9Z"
      },
      "outputs": [],
      "source": [
        "def choose_action(state):\n",
        "    if random.uniform(0, 1) < eps:\n",
        "        return random.choice(ACTIONS) \n",
        "    else:\n",
        "        return np.argmax(q(state))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU_o8-m6Dw9Z",
        "outputId": "5cd30f2b-63c1-4507-c3d3-dfb9302b48db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1: total reward -> 999\n",
            "Episode 2: total reward -> 998\n",
            "Episode 3: total reward -> 997\n",
            "Episode 4: total reward -> 997\n",
            "Episode 5: total reward -> 999\n",
            "Episode 6: total reward -> 999\n",
            "Episode 7: total reward -> 998\n",
            "Episode 8: total reward -> -100\n",
            "Episode 9: total reward -> -101\n",
            "Episode 10: total reward -> 999\n",
            "Episode 11: total reward -> 999\n",
            "Episode 12: total reward -> 999\n",
            "Episode 13: total reward -> 999\n",
            "Episode 14: total reward -> 999\n",
            "Episode 15: total reward -> 999\n",
            "Episode 16: total reward -> 998\n",
            "Episode 17: total reward -> 999\n",
            "Episode 18: total reward -> 999\n",
            "Episode 19: total reward -> 999\n",
            "Episode 20: total reward -> 999\n"
          ]
        }
      ],
      "source": [
        "for e in range(N_EPISODES):\n",
        "    state = start_state\n",
        "    total_reward = 0\n",
        "    alpha = alphas[e]\n",
        "\n",
        "    for _ in range(MAX_EPISODE_STEPS):\n",
        "        action = choose_action(state)\n",
        "        next_state, reward, done = act(state, action)\n",
        "        total_reward += reward\n",
        "\n",
        "        q(state)[action] = q(state, action) + \\\n",
        "                alpha * (reward + gamma *  np.max(q(next_state)) - q(state, action))\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "    print(f\"Episode {e + 1}: total reward -> {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbiEnWTeDw9Z",
        "outputId": "08d7960f-2f16-466d-d7fe-b1bc30bf3f17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1]): array([998.9999565 , 225.12936017, -85.10182825, 586.19245204]),\n",
              " State(grid=[['i', 'c'], ['z', '*']], car_pos=[0, 1]): array([ 895.94526316,  842.8767095 , 1000.        ,  967.10727091]),\n",
              " State(grid=[['ic', 'c'], ['z', '*']], car_pos=[0, 0]): array([0., 0., 0., 0.]),\n",
              " State(grid=[['i', '*'], ['zc', 'c']], car_pos=[1, 0]): array([0., 0., 0., 0.])}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo0jSvb1Dw9a",
        "outputId": "c0320974-3319-48d1-fe7d-4699bed28e56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO1DMJncDw9a",
        "outputId": "07cd8686-8d26-4a38-8784-b576adaab5fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['i', 'c'], ['z', '*']], car_pos=[0, 1])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_1 = act(start_state, choose_action(start_state))[0]\n",
        "state_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vibOf-3aDw9a",
        "outputId": "e9e7920c-c10b-48bd-f3e9-700350c5e9f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['ic', 'c'], ['z', '*']], car_pos=[0, 0])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_2 = act(state_1, choose_action(state_1))[0]\n",
        "state_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CZx67lSDw9a"
      },
      "source": [
        "# Openai Gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "dX87jXwZDw9a",
        "outputId": "70db9e5b-79fb-45ea-cba0-ba1e40221b77"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "done = False\n",
        "\n",
        "for t in range(500):\n",
        "    screen = env.render()\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _, info = env.step(action)\n",
        "    if done:\n",
        "        observation = env.reset()\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M4BSK0abDw9b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc549a49280>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(screen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyRXnxkTDw9b",
        "outputId": "081f921d-865d-4fe8-8c6d-c93048cd3ca1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.0087725 , -0.23881234,  0.09779616,  0.8087617 ], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUGchrjBDw9c",
        "outputId": "7ace4186-93c9-4861-f9d7-8c85c513ce73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Lk-IckbBDw9c"
      },
      "outputs": [],
      "source": [
        "def demo(name, n_episodes=10):\n",
        "    env = gym.make(name)\n",
        "    try:\n",
        "        for i_episode in range(n_episodes):\n",
        "            observation = env.reset()\n",
        "            for t in range(100):\n",
        "                env.render()\n",
        "                action = env.action_space.sample()\n",
        "                observation, reward, done, _, info = env.step(action)\n",
        "                if done:\n",
        "                    print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "                    break\n",
        "    finally:\n",
        "        env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z028IGOPDw9d",
        "outputId": "2c018347-3639-4006-9fa2-f73ca82ac55d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete(2)\n"
          ]
        }
      ],
      "source": [
        "print(env.action_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrpeZT8JDw9d",
        "outputId": "dabbd92f-9450-4b36-b9a5-9ed3bb15bccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss4kjZG9Dw9d",
        "outputId": "320531af-3415-44eb-aa9e-8a94c6f59456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space.high)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ZBg1LSDw9d",
        "outputId": "877034ce-9189-48cd-8325-c65beb72b699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space.low)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "M1Jqi4AQDw9d"
      },
      "outputs": [],
      "source": [
        "from gym import spaces\n",
        "space = spaces.Discrete(8) # Set with 8 elements {0, 1, 2, ..., 7}\n",
        "x = space.sample()\n",
        "assert space.contains(x)\n",
        "assert space.n == 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Virkt4-5Dw9e"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /home/sero/.local/lib/python3.8/site-packages (1.13.0+cpu)\n",
            "Requirement already satisfied: torchvision in /home/sero/.local/lib/python3.8/site-packages (0.14.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /home/sero/.local/lib/python3.8/site-packages (0.13.0+cpu)\n",
            "Requirement already satisfied: typing-extensions in /home/sero/.local/lib/python3.8/site-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: numpy in /home/sero/.local/lib/python3.8/site-packages (from torchvision) (1.22.3)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.22.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/sero/.local/lib/python3.8/site-packages (from torchvision) (9.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "97mw4fjmDw9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sero/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "use_cuda = False  # torch.cuda.is_available()\n",
        "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
        "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
        "BoolTensor = torch.cuda.BoolTensor if use_cuda else torch.BoolTensor\n",
        "Tensor = FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gHFhEgViDw9e"
      },
      "outputs": [],
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Idt8HAI_Dw9f"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        self.head = nn.Linear(448, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9nyZCWE9Dw9f",
        "outputId": "86193803-e7e4-43eb-8958-096cd968ae82"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array').unwrapped\n",
        "env.reset()\n",
        "screen = env.render()\n",
        "env.step(env.action_space.sample())\n",
        "env.close()\n",
        "plt.imshow(screen)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "uULN20vdDw9f",
        "outputId": "9839d0e8-83e3-4093-8ada-3eed83886d4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_214018/2390887256.py:3: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
            "  T.Resize(40, interpolation=Image.CUBIC),\n",
            "/home/sero/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "resize = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize(40, interpolation=Image.CUBIC),\n",
        "    T.ToTensor()\n",
        "])\n",
        "# This is based on the code from gym.\n",
        "screen_width = 600\n",
        "\n",
        "\n",
        "def get_cart_location():\n",
        "    world_width = env.x_threshold * 2\n",
        "    scale = screen_width / world_width\n",
        "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
        "\n",
        "\n",
        "def get_screen():\n",
        "    screen = env.render().transpose((2, 0, 1))\n",
        "    screen = screen[:, 160:320]\n",
        "    view_width = 320\n",
        "    cart_location = get_cart_location()\n",
        "    if cart_location < view_width // 2:\n",
        "        slice_range = slice(view_width)\n",
        "    elif cart_location > (screen_width - view_width // 2):\n",
        "        slice_range = slice(-view_width, None)\n",
        "    else:\n",
        "        slice_range = slice(cart_location - view_width // 2,\n",
        "                            cart_location + view_width // 2)\n",
        "    # Strip off the edges, so that we have a square image centered on a cart\n",
        "    screen = screen[:, :, slice_range]\n",
        "    # Convert to float, rescare, convert to torch tensor\n",
        "    # (this doesn't require a copy)\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    screen = torch.from_numpy(screen)\n",
        "    # Resize, and add a batch dimension (BCHW)\n",
        "    return resize(screen).unsqueeze(0).type(Tensor)\n",
        "\n",
        "\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array').unwrapped\n",
        "env.reset()\n",
        "env.step(env.action_space.sample())\n",
        "plt.figure()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_OCB1FsCDw9g"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "policy_net = DQN()\n",
        "target_net = DQN()\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "if use_cuda:\n",
        "    policy_net.cuda()\n",
        "    target_net.cuda()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters())\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state.type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return LongTensor([[random.randrange(2)]])\n",
        "\n",
        "\n",
        "episode_durations = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0EsPBnhGDw9g"
      },
      "outputs": [],
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation).\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    non_final_mask = BoolTensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)))\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                       if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE).type(Tensor)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "va9jxIE7Dw9h"
      },
      "outputs": [],
      "source": [
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.FloatTensor(episode_durations)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        display.clear_output(wait=True)\n",
        "    #     display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_final_result():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.FloatTensor(episode_durations)\n",
        "    plt.title('Training curve.')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    plt.savefig('training.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_tIYPtFDw9h",
        "outputId": "d518b930-c692-4e93-cd2a-620128fc1ed0"
      },
      "outputs": [],
      "source": [
        "num_episodes = 50\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and state\n",
        "    env.reset()\n",
        "    last_screen = get_screen()\n",
        "    current_screen = get_screen()\n",
        "    state = current_screen - last_screen\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        action = select_action(state)\n",
        "        _, reward, done, _, info = env.step(action[0, 0].item())\n",
        "        reward = Tensor([reward])\n",
        "\n",
        "        # Observe new state\n",
        "        last_screen = current_screen\n",
        "        current_screen = get_screen()\n",
        "        if not done:\n",
        "            next_state = current_screen - last_screen\n",
        "        else:\n",
        "            next_state = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the target network)\n",
        "        optimize_model()\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "\n",
        "            break\n",
        "    # Update the target network\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "plot_final_result()\n",
        "print('Complete')\n",
        "env.close()\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hLO9FQmZDw9i"
      },
      "outputs": [],
      "source": [
        "tran = memory.sample(1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_C6Nt3mQDw9i",
        "outputId": "a34df7ed-3fdb-4152-fd3c-690eea816491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdba13ec220>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(tran.state.cpu().squeeze(0).permute(1, 2, 0).numpy() + 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Z6ZdmnwkDw9i",
        "outputId": "87302363-2921-4986-814a-4d3c97415da9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1219"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "YitlD1mCDw9j"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
