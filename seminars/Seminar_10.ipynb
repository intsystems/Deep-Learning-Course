{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugixb2FtDw9M"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| ![gym](https://github.com/nadiinchi/dl_labs/blob/master/images/gym.png?raw=1) | ![img](https://github.com/nadiinchi/dl_labs/blob/master/images/pytorch.png?raw=1) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cg6xuMm-Dw9P"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install gym pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRZeB_EPDw9S"
      },
      "source": [
        "Agent interacts with the environment through actions (**A**), changing its state (**S**) and getting the reward (**R**).\n",
        "\n",
        "The final goal is to maximize a total reward.\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/recap.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUzG6P3kDw9R"
      },
      "source": [
        "# Reinforcement Learning Recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIETtGs7Dw9S"
      },
      "source": [
        "## Cart-Pole\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/cartpole.png?raw=1)\n",
        "\n",
        "* **Task** - keep the pole vertical as long as possible\n",
        "* **State** - angle, rotation speed, position, velocity\n",
        "* **Action** - horizontal force, applied to the cart\n",
        "* **Reward** - 1 for each moment with almost-vertical pole (e.g., 85-95 degrees)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FviqdWkkDw9S"
      },
      "source": [
        "## Atari\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/atari.png?raw=1)\n",
        "\n",
        "* **Task** - get as many points as possible\n",
        "* **State** - game screen (screenshots)\n",
        "* **Action** - various buttons\n",
        "* **Reward** - is defined by a particular game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s01YW65Dw9T"
      },
      "source": [
        "## Doom\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/doom.png?raw=1)\n",
        "\n",
        "* **Target** - kill 'em all\n",
        "* **State** - game screen (screenshots)\n",
        "* **Action** - various buttons\n",
        "* **Reward** - +1 for killing an enemy, -N for dying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1ElZlN7Dw9T"
      },
      "source": [
        "## Discounted reward\n",
        "\n",
        "It is common to use a discount factor $\\gamma$ to give higher weights for closer rewards.\n",
        "\n",
        "Without the dicounted factor a total reward for all the states after $t$ can be defined as\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/nodiscount.png?raw=1)\n",
        "\n",
        "With the discounted factor we focus on the current rewards as the state can change in the future:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/discount.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s53pPf7mDw9T"
      },
      "source": [
        "## Value function\n",
        "\n",
        "We want to know how good (valuable) each state is. It would help us to choose the best state to go.\n",
        "\n",
        "The value function represent how good is a state for an agent to be in. It is equal to expected total reward for an agent starting from state s. The value function depends on the policy by which the agent picks actions to perform. So, if the agent uses a given policy $\\pi$ to select actions, the corresponding value function is given by\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/vpolicy.png?raw=1)\n",
        "\n",
        "Among all possible value-functions, there exist an **optimal value function** that has higher value than other functions for all states:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/voptimal.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSwnQ6nHDw9T"
      },
      "source": [
        "## Q-function\n",
        "\n",
        "Even having optimal value functions we can't just choose the best state, only to choose an action `a`.\n",
        "\n",
        "For better actions choice there is a quality-function Q defining the effectiveness of such actions.\n",
        "\n",
        "$Q^\\pi(s, a)$ is defined as an expected reward for making action `a` and following $\\pi$ afterwards.\n",
        "\n",
        "Just like with the value function, there is an optimal $Q^*(s, a)$\n",
        "\n",
        "Since $V^*(s)$ is the maximum expected total reward when starting from state `s`, it will be the maximum of $Q^*(s, a)$ over all possible actions. Therefore, the relationship between $Q^*(s, a)$ and $V^*(s)$ is easily obtained as:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/VQ.png?raw=1)\n",
        "\n",
        "The optimal strategy is therefore derived from the optimal $Q$:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/pioptimal.png?raw=1)\n",
        "\n",
        "As the result **the task** of optimal strategy search for an agent **is** reduced to **defining $V^*$ Ð¸ $Q^*$**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBO-Yt_wDw9U"
      },
      "source": [
        "## Q-learning\n",
        "\n",
        "$Q(s, a)$ is defined recursevly through the Bellman equation as\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/bellman.png?raw=1)\n",
        "\n",
        "The Q-learning idea is to estimate Q iteratively w.r.t. the Bellman equation:\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/qiter.png?raw=1)\n",
        "\n",
        "The initial approximations will be random but the more the agent knows the closer we are to $Q^*$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKayt6geDw9U"
      },
      "source": [
        "# \"Handmade\" environment\n",
        "\n",
        "![](https://github.com/nadiinchi/dl_labs/blob/master/images/zombie.png?raw=1)\n",
        "\n",
        "We want to find an icecream and not to be eaten by zombie at the same time.\n",
        "\n",
        "Our action is chosen from 4 directions to go from the current cell.\n",
        "\n",
        "Initial state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3QXsAdgDw9V",
        "outputId": "c612e07c-f4fb-41b1-e8f8-c45e336fe5bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i *\n",
            "z c\n"
          ]
        }
      ],
      "source": [
        "ZOMBIE = \"z\"\n",
        "CAR = \"c\"\n",
        "ICE_CREAM = \"i\"\n",
        "EMPTY = \"*\"\n",
        "\n",
        "grid = [\n",
        "    [ICE_CREAM, EMPTY],\n",
        "    [ZOMBIE, CAR]\n",
        "]\n",
        "\n",
        "for row in grid:\n",
        "    print(' '.join(row))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq-vH80jDw9X"
      },
      "source": [
        "State class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "58jxQuP6Dw9X"
      },
      "outputs": [],
      "source": [
        "class State:\n",
        "    def __init__(self, grid, car_pos):\n",
        "        self.grid = grid\n",
        "        self.car_pos = car_pos\n",
        "        \n",
        "    def __eq__(self, other):\n",
        "        return isinstance(other, State) and self.grid == other.grid and self.car_pos == other.car_pos\n",
        "    \n",
        "    def __hash__(self):\n",
        "        return hash(str(self.grid) + str(self.car_pos))\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"State(grid={self.grid}, car_pos={self.car_pos})\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQAYJRRSDw9X"
      },
      "source": [
        "Actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQqJahc0Dw9X"
      },
      "outputs": [],
      "source": [
        "UP = 0\n",
        "DOWN = 1\n",
        "LEFT = 2\n",
        "RIGHT = 3\n",
        "\n",
        "ACTIONS = [UP, DOWN, LEFT, RIGHT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHlGqHK2Dw9X"
      },
      "source": [
        "Initial state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRWFzireDw9Y",
        "outputId": "82f54865-f727-4ec6-b201-452f50af9ecc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_state = State(grid=grid, car_pos=[1, 1])\n",
        "start_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsQQUVJkDw9Y"
      },
      "source": [
        "Action functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YOtkP0-ADw9Y"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def act(state, action):\n",
        "    def new_car_pos(state, action):\n",
        "        p = deepcopy(state.car_pos)\n",
        "        if action == UP:\n",
        "            p[0] = max(0, p[0] - 1)\n",
        "        elif action == DOWN:\n",
        "            p[0] = min(len(state.grid) - 1, p[0] + 1)\n",
        "        elif action == LEFT:\n",
        "            p[1] = max(0, p[1] - 1)\n",
        "        elif action == RIGHT:\n",
        "            p[1] = min(len(state.grid[0]) - 1, p[1] + 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown action {action}\")\n",
        "        return p\n",
        "\n",
        "    p = new_car_pos(state, action)\n",
        "    grid_item = state.grid[p[0]][p[1]]\n",
        "    \n",
        "    new_grid = deepcopy(state.grid)\n",
        "    \n",
        "    if grid_item == ZOMBIE:\n",
        "        reward = -100\n",
        "        is_done = True\n",
        "        new_grid[p[0]][p[1]] += CAR\n",
        "    elif grid_item == ICE_CREAM:\n",
        "        reward = 1000\n",
        "        is_done = True\n",
        "        new_grid[p[0]][p[1]] += CAR\n",
        "    elif grid_item == EMPTY:\n",
        "        reward = -1\n",
        "        is_done = False\n",
        "        old = state.car_pos\n",
        "        new_grid[old[0]][old[1]] = EMPTY\n",
        "        new_grid[p[0]][p[1]] = CAR\n",
        "    elif grid_item == CAR:\n",
        "        reward = -1\n",
        "        is_done = False\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown grid item {grid_item}\")\n",
        "\n",
        "    return State(grid=new_grid, car_pos=p), reward, is_done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8NxgC6XDw9Y"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7UqGybjuDw9Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "N_STATES = 4\n",
        "N_EPISODES = 20\n",
        "\n",
        "MAX_EPISODE_STEPS = 100\n",
        "\n",
        "MIN_ALPHA = 0.02\n",
        "\n",
        "alphas = np.linspace(1.0, MIN_ALPHA, N_EPISODES)\n",
        "gamma = 1.0\n",
        "eps = 0.2\n",
        "\n",
        "q_table = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RNjLdm0bDw9Z"
      },
      "outputs": [],
      "source": [
        "def q(state, action=None):\n",
        "    if state not in q_table:\n",
        "        q_table[state] = np.zeros(len(ACTIONS))\n",
        "\n",
        "    if action is None:\n",
        "        return q_table[state]\n",
        "\n",
        "    return q_table[state][action]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "plk_MayUDw9Z"
      },
      "outputs": [],
      "source": [
        "def choose_action(state):\n",
        "    if random.uniform(0, 1) < eps:\n",
        "        return random.choice(ACTIONS) \n",
        "    else:\n",
        "        return np.argmax(q(state))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU_o8-m6Dw9Z",
        "outputId": "5cd30f2b-63c1-4507-c3d3-dfb9302b48db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1: total reward -> 999\n",
            "Episode 2: total reward -> 998\n",
            "Episode 3: total reward -> 997\n",
            "Episode 4: total reward -> 997\n",
            "Episode 5: total reward -> 999\n",
            "Episode 6: total reward -> 999\n",
            "Episode 7: total reward -> 998\n",
            "Episode 8: total reward -> -100\n",
            "Episode 9: total reward -> -101\n",
            "Episode 10: total reward -> 999\n",
            "Episode 11: total reward -> 999\n",
            "Episode 12: total reward -> 999\n",
            "Episode 13: total reward -> 999\n",
            "Episode 14: total reward -> 999\n",
            "Episode 15: total reward -> 999\n",
            "Episode 16: total reward -> 998\n",
            "Episode 17: total reward -> 999\n",
            "Episode 18: total reward -> 999\n",
            "Episode 19: total reward -> 999\n",
            "Episode 20: total reward -> 999\n"
          ]
        }
      ],
      "source": [
        "for e in range(N_EPISODES):\n",
        "    state = start_state\n",
        "    total_reward = 0\n",
        "    alpha = alphas[e]\n",
        "\n",
        "    for _ in range(MAX_EPISODE_STEPS):\n",
        "        action = choose_action(state)\n",
        "        next_state, reward, done = act(state, action)\n",
        "        total_reward += reward\n",
        "\n",
        "        q(state)[action] = q(state, action) + \\\n",
        "                alpha * (reward + gamma *  np.max(q(next_state)) - q(state, action))\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "    print(f\"Episode {e + 1}: total reward -> {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbiEnWTeDw9Z",
        "outputId": "08d7960f-2f16-466d-d7fe-b1bc30bf3f17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1]): array([998.9999565 , 225.12936017, -85.10182825, 586.19245204]),\n",
              " State(grid=[['i', 'c'], ['z', '*']], car_pos=[0, 1]): array([ 895.94526316,  842.8767095 , 1000.        ,  967.10727091]),\n",
              " State(grid=[['ic', 'c'], ['z', '*']], car_pos=[0, 0]): array([0., 0., 0., 0.]),\n",
              " State(grid=[['i', '*'], ['zc', 'c']], car_pos=[1, 0]): array([0., 0., 0., 0.])}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo0jSvb1Dw9a",
        "outputId": "c0320974-3319-48d1-fe7d-4699bed28e56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['i', '*'], ['z', 'c']], car_pos=[1, 1])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO1DMJncDw9a",
        "outputId": "07cd8686-8d26-4a38-8784-b576adaab5fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['i', 'c'], ['z', '*']], car_pos=[0, 1])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_1 = act(start_state, choose_action(start_state))[0]\n",
        "state_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vibOf-3aDw9a",
        "outputId": "e9e7920c-c10b-48bd-f3e9-700350c5e9f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State(grid=[['ic', 'c'], ['z', '*']], car_pos=[0, 0])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_2 = act(state_1, choose_action(state_1))[0]\n",
        "state_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CZx67lSDw9a"
      },
      "source": [
        "# Openai Gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "dX87jXwZDw9a",
        "outputId": "70db9e5b-79fb-45ea-cba0-ba1e40221b77"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "done = False\n",
        "\n",
        "for t in range(500):\n",
        "    screen = env.render()\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _, info = env.step(action)\n",
        "    if done:\n",
        "        observation = env.reset()\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "M4BSK0abDw9b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdbc6f3a1f0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAU0ElEQVR4nO3dfYxd9Z3f8fdnZmxDgPLkgbi2WZPEScRWGxPNEqIkUpYouwS1dTZKI2i1QRGStxKREilNC1upm0hF2pUaaFG3qGxhQ6JsgC5JoSzbLEuoVqkaiEkcnk1M4oAdG9s8GPPkh5lv/5hjcmuPPXeeuPfMfb+kq3vO95x77/cnLh8OvznnnlQVkqT2GOp1A5KkmTG4JallDG5JahmDW5JaxuCWpJYxuCWpZRYsuJNcnGRzki1Jrlqoz5GkQZOFOI87yTDwFPBxYBvwI+Cyqnp83j9MkgbMQh1xXwBsqaqfV9UB4FZg/QJ9liQNlJEFet+VwLMd69uADxxr5+XLl9eaNWsWqBVJap+tW7eyZ8+eTLVtoYJ7Wkk2ABsAzjnnHDZu3NirViSp74yNjR1z20JNlWwHVnesr2pqb6qqG6tqrKrGRkdHF6gNSVp8Fiq4fwSsTXJukqXApcBdC/RZkjRQFmSqpKoOJfk88D1gGLi5qh5biM+SpEGzYHPcVXUPcM9Cvb8kDSqvnJSkljG4JallDG5JahmDW5JaxuCWpJYxuCWpZQxuSWoZg1uSWsbglqSWMbglqWUMbklqGYNbklrG4JakljG4JallDG5JahmDW5JaxuCWpJYxuCWpZeZ067IkW4F9wDhwqKrGkpwB3AasAbYCn6mqF+fWpiTpsPk44v6dqlpXVWPN+lXAfVW1FrivWZckzZOFmCpZD9zSLN8CfHIBPkOSBtZcg7uAv03yUJINTe3sqtrRLO8Ezp7jZ0iSOsxpjhv4cFVtT3IWcG+SJzs3VlUlqale2AT9BoBzzjlnjm1I0uCY0xF3VW1vnncB3wUuAJ5LsgKged51jNfeWFVjVTU2Ojo6lzYkaaDMOriTnJTklMPLwO8CjwJ3AZc3u10O3DnXJiVJvzaXqZKzge8mOfw+f1lV/yvJj4Dbk1wB/BL4zNzblCQdNuvgrqqfA++bov488LG5NCVJOjavnJSkljG4JallDG5JahmDW5JaxuCWpJYxuCWpZQxuSWoZg1uSWsbglqSWMbglqWUMbklqGYNbklrG4JakljG4JallDG5JahmDW5JaxuCWpJYxuCWpZQxuSWqZaYM7yc1JdiV5tKN2RpJ7k/yseT69qSfJ9Um2JHk4yfsXsnlJGkTdHHF/Hbj4iNpVwH1VtRa4r1kH+ASwtnlsAG6YnzYlSYdNG9xV9ffAC0eU1wO3NMu3AJ/sqH+jJv0QOC3JinnqVZLE7Oe4z66qHc3yTuDsZnkl8GzHftua2lGSbEiyMcnG3bt3z7INSRo8c/7jZFUVULN43Y1VNVZVY6Ojo3NtQ5IGxmyD+7nDUyDN866mvh1Y3bHfqqYmSZonsw3uu4DLm+XLgTs76p9tzi65ENjbMaUiSZoHI9PtkOTbwEeB5Um2AX8M/Alwe5IrgF8Cn2l2vwe4BNgCvAZ8bgF6lqSBNm1wV9Vlx9j0sSn2LeDKuTYlSTo2r5yUpJYxuCWpZQxuSWoZg1uSWsbglqSWMbglqWUMbklqGYNbklrG4JakljG4JallDG5JahmDW5JaxuCWpJYxuCWpZQxuSWoZg1uSWsbglqSWMbglqWWmDe4kNyfZleTRjtpXkmxPsql5XNKx7eokW5JsTvJ7C9W4JA2qbo64vw5cPEX9uqpa1zzuAUhyHnAp8JvNa/5LkuH5alaS1EVwV9XfAy90+X7rgVuran9V/YLJu71fMIf+JElHmMsc9+eTPNxMpZze1FYCz3bss62pHSXJhiQbk2zcvXv3HNqQpMEy2+C+AXgnsA7YAXxtpm9QVTdW1VhVjY2Ojs6yDUkaPLMK7qp6rqrGq2oC+HN+PR2yHVjdseuqpiZJmiezCu4kKzpWfx84fMbJXcClSZYlORdYCzw4txYlSZ1GptshybeBjwLLk2wD/hj4aJJ1QAFbgT8EqKrHktwOPA4cAq6sqvEF6VySBtS0wV1Vl01Rvuk4+18DXDOXpiRJx+aVk5LUMga3JLWMwS1JLWNwS1LLGNyS1DLTnlUiLUb7X97D/n17jqovO2U5y/7B8h50JHXP4NZA2vPU/+VXD/3Po+orzr+Elb+9niQ96ErqjlMlUoeJQ/uhqtdtSMdlcEsdJg4dYPIneKT+ZXBLHcYPHmDylxyk/mVwSx0mDh1wqkR9z+DWQBpZ9jbI0V//g6/tZWLC30VTfzO4NZDetvwchkaWHlV//YVt1KEDPehI6p7BrYE0tGSZp/yptQxuDaSh4aVTTpVIbeA3VwNpaMlSj7jVWga3BtLQyFIwuNVSBrcG0tDwEsLUwV2eDqg+N21wJ1md5P4kjyd5LMkXmvoZSe5N8rPm+fSmniTXJ9mS5OEk71/oQUjzpmryXG6pj3VzxH0I+FJVnQdcCFyZ5DzgKuC+qloL3NesA3yCybu7rwU2ADfMe9fSAilg/OD+XrchHde0wV1VO6rqx83yPuAJYCWwHril2e0W4JPN8nrgGzXph8BpSVbMd+PSwigmDG71uRnNcSdZA5wPPACcXVU7mk07gbOb5ZXAsx0v29bUjnyvDUk2Jtm4e/fumfYtLYxqfiFQ6mNdB3eSk4E7gC9W1cud22ryrzkz+otOVd1YVWNVNTY6OjqTl0oLqJwqUd/rKriTLGEytL9VVd9pys8dngJpnnc19e3A6o6Xr2pqUt/I0DAnvf2dR9VrYpxXnnu6Bx1J3evmrJIANwFPVNW1HZvuAi5vli8H7uyof7Y5u+RCYG/HlIrUF5Kw5MRTp9w2cfCNt7gbaWa6uXXZh4A/AB5Jsqmp/RHwJ8DtSa4Afgl8ptl2D3AJsAV4DfjcfDYszY8wvGRZr5uQZmXa4K6qH8AxrlSAj02xfwFXzrEvaWEFhkYMbrWTV05qQIXhJUf/rKvUBga3Btbxjri97F39zODWQEoCQ1PPAE6MH/L2ZeprBrd0hIlDB73Tu/qawS0docYNbvU3g1s6wsT4AZgwuNW/DG7pCE6VqN8Z3BpYS044mQwffSnDwdf2+kNT6msGtwbWCae+nZGlbzuqvn/fHsYPGNzqXwa3BlZGlsLQcK/bkGbM4NbAGhpZQuK/Amofv7UaWEPDS8iQ/wqoffzWamAd/4jbKyfVvwxuDaxkGDL1Ze81Mf4WdyN1z+CWjuR9J9XnDG5pCt53Uv3M4JamMGFwq48Z3NIUPOJWP+vmZsGrk9yf5PEkjyX5QlP/SpLtSTY1j0s6XnN1ki1JNif5vYUcgDRrgWWnLJ9iQ/H6i796y9uRutXNzYIPAV+qqh8nOQV4KMm9zbbrquo/dO6c5DzgUuA3gX8I/F2Sd1eVf6ZXnwknnrGSvc8+etSWN17a2YN+pO5Me8RdVTuq6sfN8j7gCWDlcV6yHri1qvZX1S+YvNv7BfPRrDTfhpac0OsWpBmb0Rx3kjXA+cADTenzSR5OcnOS05vaSuDZjpdt4/hBL/XM8BLv9K726Tq4k5wM3AF8sapeBm4A3gmsA3YAX5vJByfZkGRjko27d++eyUuleTNkcKuFugruJEuYDO1vVdV3AKrquaoar8lfnP9zfj0dsh1Y3fHyVU3t/1NVN1bVWFWNjY6OzmUM0qx5xK026uaskgA3AU9U1bUd9RUdu/0+cPgvPHcBlyZZluRcYC3w4Py1LM2foZGlU2+oorzTu/pUN2eVfAj4A+CRJJua2h8BlyVZx+Sv8WwF/hCgqh5LcjvwOJNnpFzpGSXqR5PHJFP/VsnExCFqYnzKO+RIvTbtt7KqfsDU3+57jvOaa4Br5tCX1FM1PhncGNzqQ145KU1h4nBwS33I4JamUOMHDW71LYNbAy0ZmvI3uScOHaDGD/WgI2l6BrcG2gmnnsXSk04/qv7GS89x4NUXe9CRND2DWwMtI0uOceaIpwOqfxncGmhDwyNkaLjXbUgzYnBroGXI4Fb7GNwaaB5xq40Mbg20DI8wNHSsi2yc41Z/Mrg10CZPB5x6W40ffGubkbpkcEvH4H0n1a8MbukYDG71K39BR4vS66+/zqZNm7o6F3vk5X1TzpY8/dSTPLW7u8vezzzzTN7znvfMsEtpdgxuLUrPPPMMH/nIRxgfnz54b/xX/4R173r7UfXrr/saf3nfI1193qc+9SnuuOOOGfcpzYZTJRp4P//VC0xU2H1gFY+/ciFbXjuf18dP4r2/sbzXrUlT8ohbA2/rzpd55o3z2PzqB5hgGCh27n8Hp57qvVDVnzzi1sDb+eqpTWiPMHlu4BD7xs/ksVc/1OvWpCkZ3Bp4r+6fYLyOvnryUC3pQTfS9Lq5WfAJSR5M8tMkjyX5alM/N8kDSbYkuS3J0qa+rFnf0mxfs8BjkObkwP5XWTp09Kl/Jw690oNupOl1c8S9H7ioqt4HrAMuTnIh8KfAdVX1LuBF4Ipm/yuAF5v6dc1+Ut8aGd/Fb53yv1k29CowwRCHOGvpVs47+f/0ujVpSt3cLLiAw4ceS5pHARcB/7yp3wJ8BbgBWN8sA/wV8J+TpI5zQu3BgwfZuXPnLNqXprZnz56uf0/7Fzte4r/d/i1eHf9rXjp0FiM5wPKl29j78r6uP++NN97wO6x5dfDgsX9yoauzSpIMAw8B7wL+DHgaeKmqDt/baRuwslleCTwLUFWHkuwFzgT2HOv9n3/+eb75zW9204rUld27d3cd3C/se53/8YMn5/R5zzzzjN9hzavnn3/+mNu6Cu6qGgfWJTkN+C7w3rk2lWQDsAHgnHPO4ctf/vJc31J60+bNm7n22mu7ugBnPrz73e/2O6x5ddtttx1z24zOKqmql4D7gQ8CpyU5HPyrgO3N8nZgNUCz/VTgqP90VNWNVTVWVWOjo6MzaUOSBlo3Z5WMNkfaJDkR+DjwBJMB/ulmt8uBO5vlu5p1mu3fP978tiRpZrqZKlkB3NLMcw8Bt1fV3UkeB25N8u+BnwA3NfvfBHwzyRbgBeDSBehbkgZWN2eVPAycP0X958AFU9TfAP7ZvHQnSTqKV05KUssY3JLUMv46oBalk08+mfXr1zMxMfGWfN4FFxw1aygtGINbi9LKlSu9sYEWLadKJKllDG5JahmDW5JaxuCWpJYxuCWpZQxuSWoZg1uSWsbglqSWMbglqWUMbklqGYNbklrG4JakljG4JallDG5JaplubhZ8QpIHk/w0yWNJvtrUv57kF0k2NY91TT1Jrk+yJcnDSd6/wGOQpIHSze9x7wcuqqpXkiwBfpDkb5ptX66qvzpi/08Aa5vHB4AbmmdJ0jyY9oi7Jr3SrC5pHnWcl6wHvtG87ofAaUlWzL1VSRJ0OcedZDjJJmAXcG9VPdBsuqaZDrkuybKmthJ4tuPl25qaJGkedBXcVTVeVeuAVcAFSf4RcDXwXuC3gTOAfzOTD06yIcnGJBt37949s64laYDN6KySqnoJuB+4uKp2NNMh+4G/AA7fLXU7sLrjZaua2pHvdWNVjVXV2Ojo6Kyal6RB1M1ZJaNJTmuWTwQ+Djx5eN46SYBPAo82L7kL+GxzdsmFwN6q2rEAvUvSQOrmrJIVwC1JhpkM+tur6u4k308yCgTYBPzLZv97gEuALcBrwOfmvWtJGmDTBndVPQycP0X9omPsX8CVc29NkjQVr5yUpJYxuCWpZQxuSWoZg1uSWsbglqSWMbglqWUMbklqGYNbklrG4JakljG4JallDG5JahmDW5JaxuCWpJYxuCWpZQxuSWoZg1uSWsbglqSWMbglqWUMbklqGYNbklrG4JakljG4JallUlW97oEk+4DNve5jgSwH9vS6iQWwWMcFi3dsjqtdfqOqRqfaMPJWd3IMm6tqrNdNLIQkGxfj2BbruGDxjs1xLR5OlUhSyxjcktQy/RLcN/a6gQW0WMe2WMcFi3dsjmuR6Is/TkqSutcvR9ySpC71PLiTXJxkc5ItSa7qdT8zleTmJLuSPNpROyPJvUl+1jyf3tST5PpmrA8neX/vOj++JKuT3J/k8SSPJflCU2/12JKckOTBJD9txvXVpn5ukgea/m9LsrSpL2vWtzTb1/R0ANNIMpzkJ0nubtYXy7i2JnkkyaYkG5taq7+Lc9HT4E4yDPwZ8AngPOCyJOf1sqdZ+Dpw8RG1q4D7qmotcF+zDpPjXNs8NgA3vEU9zsYh4EtVdR5wIXBl88+m7WPbD1xUVe8D1gEXJ7kQ+FPguqp6F/AicEWz/xXAi039uma/fvYF4ImO9cUyLoDfqap1Haf+tf27OHtV1bMH8EHgex3rVwNX97KnWY5jDfBox/pmYEWzvILJ89QB/itw2VT79fsDuBP4+GIaG/A24MfAB5i8gGOkqb/5vQS+B3ywWR5p9kuvez/GeFYxGWAXAXcDWQzjanrcCiw/orZovoszffR6qmQl8GzH+ram1nZnV9WOZnkncHaz3MrxNv8bfT7wAItgbM10wiZgF3Av8DTwUlUdanbp7P3NcTXb9wJnvqUNd+8/Av8amGjWz2RxjAuggL9N8lCSDU2t9d/F2eqXKycXraqqJK09dSfJycAdwBer6uUkb25r69iqahxYl+Q04LvAe3vb0dwl+cfArqp6KMlHe9zOQvhwVW1PchZwb5InOze29bs4W70+4t4OrO5YX9XU2u65JCsAmuddTb1V402yhMnQ/lZVfacpL4qxAVTVS8D9TE4hnJbk8IFMZ+9vjqvZfirw/FvbaVc+BPzTJFuBW5mcLvlPtH9cAFTV9uZ5F5P/sb2ARfRdnKleB/ePgLXNX76XApcCd/W4p/lwF3B5s3w5k/PDh+ufbf7qfSGwt+N/9fpKJg+tbwKeqKprOza1emxJRpsjbZKcyOS8/RNMBvinm92OHNfh8X4a+H41E6f9pKqurqpVVbWGyX+Pvl9V/4KWjwsgyUlJTjm8DPwu8Cgt/y7OSa8n2YFLgKeYnGf8t73uZxb9fxvYARxkci7tCibnCu8Dfgb8HXBGs2+YPIvmaeARYKzX/R9nXB9mcl7xYWBT87ik7WMDfgv4STOuR4F/19TfATwIbAH+O7CsqZ/QrG9ptr+j12PoYowfBe5eLONqxvDT5vHY4Zxo+3dxLg+vnJSklun1VIkkaYYMbklqGYNbklrG4JakljG4JallDG5JahmDW5JaxuCWpJb5f4lcOSF5dOhdAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(screen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyRXnxkTDw9b",
        "outputId": "081f921d-865d-4fe8-8c6d-c93048cd3ca1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.01462784,  0.41079035, -0.06409073, -0.6715171 ], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUGchrjBDw9c",
        "outputId": "7ace4186-93c9-4861-f9d7-8c85c513ce73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Lk-IckbBDw9c"
      },
      "outputs": [],
      "source": [
        "def demo(name, n_episodes=10):\n",
        "    env = gym.make(name)\n",
        "    try:\n",
        "        for i_episode in range(n_episodes):\n",
        "            observation = env.reset()\n",
        "            for t in range(100):\n",
        "                env.render()\n",
        "                action = env.action_space.sample()\n",
        "                observation, reward, done, _, info = env.step(action)\n",
        "                if done:\n",
        "                    print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "                    break\n",
        "    finally:\n",
        "        env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z028IGOPDw9d",
        "outputId": "2c018347-3639-4006-9fa2-f73ca82ac55d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete(2)\n"
          ]
        }
      ],
      "source": [
        "print(env.action_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrpeZT8JDw9d",
        "outputId": "dabbd92f-9450-4b36-b9a5-9ed3bb15bccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss4kjZG9Dw9d",
        "outputId": "320531af-3415-44eb-aa9e-8a94c6f59456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space.high)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ZBg1LSDw9d",
        "outputId": "877034ce-9189-48cd-8325-c65beb72b699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space.low)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "M1Jqi4AQDw9d"
      },
      "outputs": [],
      "source": [
        "from gym import spaces\n",
        "space = spaces.Discrete(8) # Set with 8 elements {0, 1, 2, ..., 7}\n",
        "x = space.sample()\n",
        "assert space.contains(x)\n",
        "assert space.n == 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Virkt4-5Dw9e"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "97mw4fjmDw9e"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "use_cuda = False  # torch.cuda.is_available()\n",
        "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
        "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
        "BoolTensor = torch.cuda.BoolTensor if use_cuda else torch.BoolTensor\n",
        "Tensor = FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gHFhEgViDw9e"
      },
      "outputs": [],
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Idt8HAI_Dw9f"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        self.head = nn.Linear(448, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9nyZCWE9Dw9f",
        "outputId": "86193803-e7e4-43eb-8958-096cd968ae82"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array').unwrapped\n",
        "env.reset()\n",
        "screen = env.render()\n",
        "env.step(env.action_space.sample())\n",
        "env.close()\n",
        "plt.imshow(screen)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uULN20vdDw9f",
        "outputId": "9839d0e8-83e3-4093-8ada-3eed83886d4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_142392/2390887256.py:3: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
            "  T.Resize(40, interpolation=Image.CUBIC),\n",
            "/home/sero/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "resize = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize(40, interpolation=Image.CUBIC),\n",
        "    T.ToTensor()\n",
        "])\n",
        "# This is based on the code from gym.\n",
        "screen_width = 600\n",
        "\n",
        "\n",
        "def get_cart_location():\n",
        "    world_width = env.x_threshold * 2\n",
        "    scale = screen_width / world_width\n",
        "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
        "\n",
        "\n",
        "def get_screen():\n",
        "    screen = env.render().transpose((2, 0, 1))\n",
        "    screen = screen[:, 160:320]\n",
        "    view_width = 320\n",
        "    cart_location = get_cart_location()\n",
        "    if cart_location < view_width // 2:\n",
        "        slice_range = slice(view_width)\n",
        "    elif cart_location > (screen_width - view_width // 2):\n",
        "        slice_range = slice(-view_width, None)\n",
        "    else:\n",
        "        slice_range = slice(cart_location - view_width // 2,\n",
        "                            cart_location + view_width // 2)\n",
        "    # Strip off the edges, so that we have a square image centered on a cart\n",
        "    screen = screen[:, :, slice_range]\n",
        "    # Convert to float, rescare, convert to torch tensor\n",
        "    # (this doesn't require a copy)\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    screen = torch.from_numpy(screen)\n",
        "    # Resize, and add a batch dimension (BCHW)\n",
        "    return resize(screen).unsqueeze(0).type(Tensor)\n",
        "\n",
        "\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array').unwrapped\n",
        "env.reset()\n",
        "env.step(env.action_space.sample())\n",
        "plt.figure()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_OCB1FsCDw9g"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "policy_net = DQN()\n",
        "target_net = DQN()\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "if use_cuda:\n",
        "    policy_net.cuda()\n",
        "    target_net.cuda()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters())\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state.type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return LongTensor([[random.randrange(2)]])\n",
        "\n",
        "\n",
        "episode_durations = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0EsPBnhGDw9g"
      },
      "outputs": [],
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation).\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    non_final_mask = BoolTensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)))\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                       if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE).type(Tensor)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "va9jxIE7Dw9h"
      },
      "outputs": [],
      "source": [
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.FloatTensor(episode_durations)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        display.clear_output(wait=True)\n",
        "    #     display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "F_tIYPtFDw9h",
        "outputId": "d518b930-c692-4e93-cd2a-620128fc1ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete\n"
          ]
        }
      ],
      "source": [
        "num_episodes = 50\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and state\n",
        "    env.reset()\n",
        "    last_screen = get_screen()\n",
        "    current_screen = get_screen()\n",
        "    state = current_screen - last_screen\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        action = select_action(state)\n",
        "        _, reward, done, _, info = env.step(action[0, 0].item())\n",
        "        reward = Tensor([reward])\n",
        "\n",
        "        # Observe new state\n",
        "        last_screen = current_screen\n",
        "        current_screen = get_screen()\n",
        "        if not done:\n",
        "            next_state = current_screen - last_screen\n",
        "        else:\n",
        "            next_state = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the target network)\n",
        "        optimize_model()\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            break\n",
        "    # Update the target network\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "print('Complete')\n",
        "env.close()\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hLO9FQmZDw9i"
      },
      "outputs": [],
      "source": [
        "tran = memory.sample(1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_C6Nt3mQDw9i",
        "outputId": "a34df7ed-3fdb-4152-fd3c-690eea816491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdba13ec220>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(tran.state.cpu().squeeze(0).permute(1, 2, 0).numpy() + 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Z6ZdmnwkDw9i",
        "outputId": "87302363-2921-4986-814a-4d3c97415da9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1219"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "YitlD1mCDw9j"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
