{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ffc505",
   "metadata": {},
   "source": [
    "# Реализация свёрток\n",
    "\n",
    "Этот ноутбук проведёт вас через процесс реализации достаточно эффективной операции свёртки.\n",
    "Для иллюстрации мы будем использовать нативный numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89320fe",
   "metadata": {},
   "source": [
    "## Свёртки\n",
    "\n",
    "Здесь мы построим базовые подходы к свёртке: от простого алгоритма с полными вложенными циклами\n",
    "до варианта, который использует одно матричное умножение плюс операции изменения формы/размера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434d275",
   "metadata": {},
   "source": [
    "### Порядок хранения\n",
    "\n",
    "В простых полносвязных сетях, которые мы рассматривали до сих пор, скрытые представления обычно\n",
    "хранятся как векторы, т.е. величина $z \\in \\mathbb{R}^n$, а для целого минибатча — как матрица\n",
    "$Z \\in \\mathbb{R}^{B \\times n}$. Но при переходе к свёрточным сетям нужно учитывать дополнительную\n",
    "структуру скрытого представления. Обычно каждое скрытое состояние представляют как 3D‑массив\n",
    "с размерами `height x width x channels`, а для минибатча добавляют ещё размерность батча.\n",
    "То есть скрытое представление можно хранить как массив\n",
    "\n",
    "```c++\n",
    "float Z[BATCHES][HEIGHT][WIDTH][CHANNELS];\n",
    "```\n",
    "\n",
    "Этот формат называется NHWC (number(batch)‑height‑width‑channel). Однако есть и другие варианты.\n",
    "Например, PyTorch по умолчанию использует формат NCHW (каналы во втором измерении, затем высота и ширина),\n",
    "хотя в более поздних версиях поддерживается и NHWC. Между форматами есть тонкие, но существенные различия\n",
    "по производительности: свёртки обычно быстрее в NHWC за счёт лучшего задействования tensor cores;\n",
    "а формат NCHW чаще быстрее для BatchNorm (потому что в свёрточных сетях нормализация идёт по всем пикселям\n",
    "одного канала).\n",
    "\n",
    "\n",
    "Хотя это обсуждается реже, похожий компромисс есть и для порядка хранения весов (фильтров) свёртки.\n",
    "Фильтры задаются размером ядра (теоретически он может различаться по высоте и ширине, но это редко),\n",
    "числом входных каналов и числом выходных каналов. Мы будем хранить веса в виде\n",
    "\n",
    "```c++\n",
    "float weights[KERNEL_SIZE][KERNEL_SIZE][IN_CHANNELS][OUT_CHANNELS];\n",
    "```\n",
    "\n",
    "PyTorch делает иначе (так исторически сложилось): хранит веса в порядке\n",
    "`OUT_CHANNELS x IN_CHANNELS x KERNEL_SIZE x KERNEL_SIZE`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72704412",
   "metadata": {},
   "source": [
    "## Свёртки с простыми циклами\n",
    "\n",
    "Начнём с простейшей реализации оператора свёртки. Мы сделаем вариант, который допускает разные размеры ядра,\n",
    "но **не** содержит встроенного паддинга: чтобы добавить паддинг, нужно явно создать новый ndarray с полями.\n",
    "Это означает, что если у нас входное изображение $H \\times W$ и ядро размера $K$, то на выходе получится\n",
    "изображение $(H - K + 1) \\times (W - K + 1)$.\n",
    "\n",
    "Хотя это в каком‑то смысле «чит», мы используем PyTorch как эталонную реализацию свёртки для проверки.\n",
    "Но, поскольку PyTorch использует формат NCHW (и другой порядок весов), а мы используем NHWC и порядок,\n",
    "описанный выше, нам нужно будет переставить оси перед сравнением с эталоном."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13bb47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ctypes\n",
    "from timeit import timeit\n",
    "import numpy as np\n",
    "\n",
    "def conv_reference(Z, weight):\n",
    "    # NHWC -> NCHW\n",
    "    Z_torch = torch.tensor(Z).permute(0,3,1,2)\n",
    "    \n",
    "    # KKIO -> OIKK\n",
    "    W_torch = torch.tensor(weight).permute(3,2,0,1)\n",
    "    \n",
    "    # run convolution\n",
    "    out = nn.functional.conv2d(Z_torch, W_torch)\n",
    "    \n",
    "    # NCHW -> NHWC\n",
    "    return out.permute(0,2,3,1).contiguous().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1655ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.26.4', '2.2.2')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ede64bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 30, 30, 16)\n"
     ]
    }
   ],
   "source": [
    "Z = np.random.randn(10,32,32,8)\n",
    "W = np.random.randn(3,3,8,16)\n",
    "out = conv_reference(Z,W)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fc07d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.25 ms, sys: 1.83 ms, total: 6.08 ms\n",
      "Wall time: 1.47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = conv_reference(Z,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac177dd",
   "metadata": {},
   "source": [
    "Теперь рассмотрим самый простой вариант реализации свёртки — полностью через вложенные циклы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42551005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_naive(Z, weight):\n",
    "    N,H,W,C_in = Z.shape\n",
    "    K,_,_,C_out = weight.shape\n",
    "    \n",
    "    out = np.zeros((N,H-K+1,W-K+1,C_out));\n",
    "    for n in range(N):\n",
    "        for c_in in range(C_in):\n",
    "            for c_out in range(C_out):\n",
    "                for y in range(H-K+1):\n",
    "                    for x in range(W-K+1):\n",
    "                        for i in range(K):\n",
    "                            for j in range(K):\n",
    "                                out[n,y,x,c_out] += Z[n,y+i,x+j,c_in] * weight[i,j,c_in,c_out]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f5bf9",
   "metadata": {},
   "source": [
    "Мы можем проверить корректность реализации, сравнив её с эталонной версией на PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f78a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1988119046436182e-12\n"
     ]
    }
   ],
   "source": [
    "out2 = conv_naive(Z,W)\n",
    "print(np.linalg.norm(out - out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d85fe",
   "metadata": {},
   "source": [
    "Реализация работает, но (что неудивительно: 7 вложенных циклов в коде — плохая идея)\n",
    "версия на PyTorch **гораздо** быстрее; на моём ноутбуке наивная реализация медленнее в 2000-3000 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8242fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.12 s, sys: 295 µs, total: 4.12 s\n",
      "Wall time: 4.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out2 = conv_naive(Z,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef0ec811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.4 ms, sys: 70 µs, total: 4.47 ms\n",
      "Wall time: 1.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = conv_reference(Z,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb297e2",
   "metadata": {},
   "source": [
    "## Свёртки как матричные умножения\n",
    "\n",
    "Никто не будет реализовывать свёртку поэлементно на Python. Посмотрим, как сделать намного лучше.\n",
    "Простейший способ ускорения (и в целом вполне разумная реализация) — выполнить свёртку как последовательность\n",
    "матричных умножений. Помните, что свёртка с ядром $K = 1$ эквивалентна матричному умножению по размерности каналов.\n",
    "То есть, пусть у нас есть следующая свёртка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54e2e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32, 32, 16)\n"
     ]
    }
   ],
   "source": [
    "W1 = np.random.randn(1,1,8,16)\n",
    "out = conv_reference(Z,W1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95507425",
   "metadata": {},
   "source": [
    "Тогда мы можем реализовать свёртку через **одно** матричное умножение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8c2aa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.737906132854523e-14\n"
     ]
    }
   ],
   "source": [
    "out2 = Z @ W1[0,0]\n",
    "# (10, 32, 32, 8) @ (8, 16) = (10, 32, 32, 16)\n",
    "print(np.linalg.norm(out - out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9cf7d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 16), (10, 32, 32, 16))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1[0,0].shape, out2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfef70",
   "metadata": {},
   "source": [
    "Здесь мы используем удобную особенность numpy: при умножении матриц много‑мерных массивов ведущие измерения\n",
    "трактуются как набор строк матрицы. То есть операция выше эквивалентна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb755b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = (Z.reshape(-1,8) @ W1[0,0]).reshape(Z.shape[0], Z.shape[1], Z.shape[2], W1.shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4572a4",
   "metadata": {},
   "source": [
    "Эта идея сразу подсказывает естественный подход к свёртке: можно итерироваться только по размерам ядра $i$ и $j$,\n",
    "а саму операцию свёртки выполнять через матричное умножение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f057d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_matrix_mult(Z, weight):\n",
    "    N,H,W,C_in = Z.shape\n",
    "    K,_,_,C_out = weight.shape\n",
    "    out = np.zeros((N,H-K+1,W-K+1,C_out))\n",
    "    \n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            out += Z[:,i:i+H-K+1,j:j+W-K+1,:] @ weight[i,j]\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d0b31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3081167894918336e-12\n"
     ]
    }
   ],
   "source": [
    "Z = np.random.randn(100,32,32,8)\n",
    "W = np.random.randn(3,3,8,16)\n",
    "\n",
    "out = conv_reference(Z,W)\n",
    "out2 = conv_matrix_mult(Z,W)\n",
    "print(np.linalg.norm(out - out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45785e",
   "metadata": {},
   "source": [
    "Это тоже работает и (как и ожидалось) **гораздо** быстрее, уже начинает конкурировать с PyTorch\n",
    "(на моей машине отстаёт примерно в 2–3 раза). Увеличим размер батча, чтобы операция длилась дольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa8aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 ms, sys: 24.9 ms, total: 68.8 ms\n",
      "Wall time: 8.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = conv_reference(Z,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02ee7f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.4 ms, sys: 5.97 ms, total: 38.3 ms\n",
      "Wall time: 37.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = conv_matrix_mult(Z,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1084c",
   "metadata": {},
   "source": [
    "## Страйды\n",
    "\n",
    "**Вопрос: как хранить матрицу в памяти?**\n",
    "\n",
    "Строчный формат (row major): $A[i, j] => Adata[i * A.shape[1] + j]$\n",
    "\n",
    "Колоночный формат (column major): $A[i, j] => Adata[j * A.shape[0] + i]$\n",
    "\n",
    "Формат страйдов: $A[i, j] => Adata[i * A.strides[0] + j * A.strides[1]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d013708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strides_in_elems(a):\n",
    "    return tuple(s // a.itemsize for s in a.strides)\n",
    "\n",
    "def get_addr(a, i, j):\n",
    "    return a.ctypes.data + i * a.strides[0] + j * a.strides[1]\n",
    "\n",
    "def read_scalar_via_pointer(a, i, j):\n",
    "    addr = get_addr(a, i, j)\n",
    "    if a.dtype == np.int32:\n",
    "        return ctypes.c_int.from_address(addr).value\n",
    "    elif a.dtype == np.float32:\n",
    "        return ctypes.c_float.from_address(addr).value\n",
    "    else:\n",
    "        raise TypeError(\"Используйте int32 или float32 для демо\")\n",
    "    \n",
    "def arr_as_one_dim(arr):\n",
    "    return np.frombuffer(ctypes.string_at(arr.ctypes.data, arr.nbytes), dtype=arr.dtype, count=arr.size)\n",
    "\n",
    "np.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ac04c",
   "metadata": {},
   "source": [
    "Строчный формат и колоночный формат: данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59be8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (row-major C):\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "A.shape: (3, 4) A.dtype: int32\n",
      "A.strides (bytes): (16, 4) -> in elements: (4, 1)\n",
      "A.data: [ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "B (column-major F):\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "B.strides (bytes): (4, 12) -> in elements: (1, 3)\n",
      "B.data: [ 1  5  9  2  6 10  3  7 11  4  8 12]\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(1, 13, dtype=np.int32).reshape(3, 4, order='C')  # 3x4\n",
    "print(\"A (row-major C):\\n\", A)\n",
    "print(\"A.shape:\", A.shape, \"A.dtype:\", A.dtype)\n",
    "print(\"A.strides (bytes):\", A.strides, \"-> in elements:\", strides_in_elems(A))\n",
    "print(\"A.data:\", arr_as_one_dim(A))\n",
    "\n",
    "B = np.array(A, order='F', copy=True)\n",
    "print(\"\\nB (column-major F):\\n\", B)\n",
    "print(\"B.strides (bytes):\", B.strides, \"-> in elements:\", strides_in_elems(B))\n",
    "print(\"B.data:\", arr_as_one_dim(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a99e1f0",
   "metadata": {},
   "source": [
    "Строчный формат и колоночный формат: индексирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b74e3f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка индекса (i,j) -> значение у соответствующего указателя:\n",
      "(i=0, j=0)  A[i,j]=1  via_ptr=1   |   B[i,j]=1  via_ptr=1\n",
      "(i=1, j=2)  A[i,j]=7  via_ptr=7   |   B[i,j]=7  via_ptr=7\n",
      "(i=2, j=3)  A[i,j]=12  via_ptr=12   |   B[i,j]=12  via_ptr=12\n",
      "\n",
      "Одномерный индекс для (i=1,j=2):\n",
      "C-order  i*cols + j = 6  -> A.ravel(order='C')[..] = 7\n",
      "F-order  j*rows + i = 7  -> B.ravel(order='F')[..] = 7\n"
     ]
    }
   ],
   "source": [
    "tests = [(0,0), (1,2), (2,3)]\n",
    "print(\"Проверка индекса (i,j) -> значение у соответствующего указателя:\")\n",
    "for (i,j) in tests:\n",
    "    vA = read_scalar_via_pointer(A, i, j)\n",
    "    vB = read_scalar_via_pointer(B, i, j)\n",
    "    assert A[i, j] == vA\n",
    "    assert B[i, j] == vB\n",
    "    assert A[i, j] == B[i, j]\n",
    "    \n",
    "    print(f\"(i={i}, j={j})  A[i,j]={A[i,j]}  via_ptr={vA}   |   B[i,j]={B[i,j]}  via_ptr={vB}\")\n",
    "\n",
    "rows, cols = A.shape\n",
    "i, j = 1, 2\n",
    "c_linear = i * cols + j\n",
    "f_linear = j * rows + i\n",
    "print(f\"\\nОдномерный индекс для (i={i},j={j}):\")\n",
    "print(\"C-order  i*cols + j =\", c_linear, \" -> A.ravel(order='C')[..] =\", A.ravel(order='C')[c_linear])\n",
    "print(\"F-order  j*rows + i =\", f_linear, \" -> B.ravel(order='F')[..] =\", B.ravel(order='F')[f_linear])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed74639",
   "metadata": {},
   "source": [
    "**Преимущества**: можно выполнять преобразование / слайсинг без копирования данных\n",
    "- Slice: изменить начальное смещение и форму\n",
    "- Transpose: поменять местами страйды\n",
    "- Broadcast: вставить страйд, равный 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cda57e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S разделяет память с A: True\n",
      "S.strides (bytes): (32, 4) -> в элементах: (8, 1)\n",
      "\n",
      "AT = A.T\n",
      "AT разделяет память с A: True\n",
      "AT.strides (bytes): (4, 16) -> в элементах: (1, 4)\n",
      "\n",
      "Форма исходной строки: (1, 4)\n",
      "Форма представления после broadcast: (3, 4)\n",
      "Row разделяет память с Bcast: True\n",
      "Страйды после broadcast (в байтах): (0, 4) -> в элементах: (0, 1)\n",
      "Первая строка равна второй? True\n"
     ]
    }
   ],
   "source": [
    "# Slice: изменить начальное смещение и форму — всё ещё представление (view)\n",
    "S = A[::2, 1:]\n",
    "print(\"S разделяет память с A:\", np.shares_memory(S, A))\n",
    "print(\"S.strides (bytes):\", S.strides, \"-> в элементах:\", strides_in_elems(S))\n",
    "\n",
    "# Transpose: поменять местами страйды — всё ещё представление (view)\n",
    "AT = A.T\n",
    "print(\"\\nAT = A.T\")\n",
    "print(\"AT разделяет память с A:\", np.shares_memory(AT, A))\n",
    "print(\"AT.strides (bytes):\", AT.strides, \"-> в элементах:\", strides_in_elems(AT))\n",
    "\n",
    "# Broadcasting: вставить страйд, равный 0 — всё ещё представление (view)\n",
    "row = np.arange(A.shape[1], dtype=np.int32)[None, :]  # форма (1,4)\n",
    "Bcast = np.broadcast_to(row, A.shape)                 # форма (3,4)\n",
    "print(\"\\nФорма исходной строки:\", row.shape)\n",
    "print(\"Форма представления после broadcast:\", Bcast.shape)\n",
    "print(\"Row разделяет память с Bcast:\", np.shares_memory(row, Bcast))\n",
    "print(\"Страйды после broadcast (в байтах):\", Bcast.strides, \"-> в элементах:\", strides_in_elems(Bcast))\n",
    "print(\"Первая строка равна второй?\", np.array_equal(Bcast[0], Bcast[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104fcbc",
   "metadata": {},
   "source": [
    "**Недостатки**: доступ к памяти становится прерывистым\n",
    "- Усложняет векторизацию\n",
    "- Для выполнения многих операций линейной алгебры может потребоваться сначала сделать массив \"непрерывным\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bca9b73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xc.flags: True False\n",
      "Xf.flags: False True\n",
      "XT.flags: False True\n",
      "\n",
      "Время выполнения (меньше — лучше):\n",
      "С-порядок (C-order) сумма по оси=0 (Xc): 0.040s\n",
      "Транспонированное представление (XT, не-континуальное) сумма по оси=1: 0.042s\n",
      "\n",
      "Умножение dot для не-континуального XT: 0.017s  |  После ascontiguousarray: 0.016s\n"
     ]
    }
   ],
   "source": [
    "M, N = 4000, 4000\n",
    "Xc = np.random.rand(M, N).astype(np.float64, copy=False)           # C-contiguous\n",
    "Xf = np.array(Xc, order='F', copy=True)                            # Fortran-contiguous\n",
    "XT = Xc.T                                                          # non-contiguous view\n",
    "\n",
    "print(\"Xc.flags:\", Xc.flags.c_contiguous, Xc.flags.f_contiguous)\n",
    "print(\"Xf.flags:\", Xf.flags.c_contiguous, Xf.flags.f_contiguous)\n",
    "print(\"XT.flags:\", XT.flags.c_contiguous, XT.flags.f_contiguous)\n",
    "\n",
    "# Пример: суммирование по строкам у C-contiguous (строчного) массива cache-friendly;\n",
    "# суммирование по строкам у транспонированного XT — нет, и наоборот.\n",
    "t1 = timeit(\"Xc.sum(axis=1)\", number=5, globals=globals())\n",
    "t2 = timeit(\"XT.sum(axis=0)\", number=5, globals=globals())\n",
    "print(f\"\\nВремя выполнения (меньше — лучше):\")\n",
    "print(f\"С-порядок (C-order) сумма по оси=0 (Xc): {t1:.3f}s\")\n",
    "print(f\"Транспонированное представление (XT, не-континуальное) сумма по оси=1: {t2:.3f}s\")\n",
    "\n",
    "# Многие операции линейной алгебры требуют континуальных (неразрывных) данных;\n",
    "# принудительное «упаковка» массива может улучшить производительность\n",
    "t_bad  = timeit(\"np.dot(XT, np.ones(N, dtype=np.float32))\", number=5, globals=globals())\n",
    "XTc = np.ascontiguousarray(XT)  # сделать непрерывным в памяти (упаковать)\n",
    "t_good = timeit(\"np.dot(XTc, np.ones(N, dtype=np.float32))\", number=5, globals=globals())\n",
    "print(f\"\\nУмножение dot для не-континуального XT: {t_bad:.3f}s  |  После ascontiguousarray: {t_good:.3f}s\")\n",
    "\n",
    "del Xc, Xf, XT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b64d34",
   "metadata": {},
   "source": [
    "## Манипуляции с матрицами через «страйды»\n",
    "\n",
    "Прежде чем реализовывать свёртки через im2col, рассмотрим пример, не связанный напрямую со свёрткой.\n",
    "Вспомним эффективные операции матричного умножения из предыдущей лекции. Обычно матрицу хранят как 2D‑массив:\n",
    "\n",
    "```c++\n",
    "float A[M][N];\n",
    "```\n",
    "\n",
    "В типичном порядкe row‑major каждая из N‑мерных строк хранится подряд в памяти. Однако, чтобы лучше\n",
    "использовать кэши и векторные операции современных CPU, выгодно хранить матрицу маленькими «плитками»,\n",
    "чтобы векторный блок процессора эффективно работал с блоками `TILE x TILE`:\n",
    "\n",
    "    float A[M/TILE][N/TILE][TILE][TILE];\n",
    "\n",
    "где `TILE` — небольшая константа (например, 4). В стандартном порядке памяти для ND‑массива\n",
    "такой способ укладки располагает каждый блок `TILE x TILE` подряд, что позволяет быстро\n",
    "загружать/выгружать данные в кэш/регистры и т.д.\n",
    "\n",
    "Как преобразовать матрицу к такому виду? Можно было бы вручную копировать между структурами,\n",
    "но это громоздко и требует высокопроизводительного кода на C/C++. Вместо этого воспользуемся\n",
    "функцией `np.lib.stride_tricks.as_strided()`, которая позволяет создавать новые представления массивов,\n",
    "вручную задавая страйды, **не меняя** сами данные; затем применим `np.ascontiguousarray()`,\n",
    "чтобы уложить данные последовательно. Такой приём позволяет в пару строк перестраивать матрицы довольно эффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecde2d0",
   "metadata": {},
   "source": [
    "### Пример: 2D‑массив 6x6\n",
    "\n",
    "Для наглядности возьмём пример 6x6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e3c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17.]\n",
      " [18. 19. 20. 21. 22. 23.]\n",
      " [24. 25. 26. 27. 28. 29.]\n",
      " [30. 31. 32. 33. 34. 35.]]\n"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "A = np.arange(n**2, dtype=np.float32).reshape(n,n)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce404302",
   "metadata": {},
   "source": [
    "Этот массив уложен в памяти построчно. Доступ к «сырой» памяти numpy намеренно затрудняет\n",
    "(чтобы предотвратить ошибки), но увидеть раскладку можно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65f9ae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28.\n",
      " 29. 30. 31. 32. 33. 34. 35.]\n"
     ]
    }
   ],
   "source": [
    "print(np.frombuffer(ctypes.string_at(A.ctypes.data, A.nbytes), dtype=A.dtype, count=A.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91de05b",
   "metadata": {},
   "source": [
    "Ранее мы обсуждали структуру `strides` как способ описания укладки N‑мерных массивов в памяти.\n",
    "Чтобы обратиться к элементу `A[i][j]` 2D‑массива, нужно взять адрес\n",
    "\n",
    "```c++\n",
    "A.bytes[i * strides[0] + j * strides[1]];\n",
    "```\n",
    "\n",
    "Аналогично для 3D‑тензора, элемент `A[i][j][k]` находится по адресу\n",
    "\n",
    "```c++\n",
    "A.bytes[i * strides[0] + j * strides[1] + k * strides[2]];\n",
    "```\n",
    "\n",
    "Для формата row‑major получим\n",
    "\n",
    "```c++\n",
    "strides[0] = num_cols;\n",
    "strides[1] = 1;\n",
    "```\n",
    "\n",
    "Узнать страйды массива можно через свойство `.strides`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d86b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4)\n"
     ]
    }
   ],
   "source": [
    "print(A.strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a096133",
   "metadata": {},
   "source": [
    "Учтите, что numpy хранит страйды в **байтах**, поэтому числа умножены на 4 (тип `float32` занимает 4 байта).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4705674",
   "metadata": {},
   "source": [
    "### Плиточное разбиение матрицы (matrix tiling) через страйды\n",
    "\n",
    "Построим представление `A` в виде плиток, **только** меняя страйды. Для простоты разобьём на блоки 2x2,\n",
    "т.е. хотим получить массив `3 x 3 x 2 x 2`. Какие должны быть страйды? При обращении к `A[i][j][k][l]`:\n",
    "увеличение `i` сдвигает нас на две строки вниз (`strides[0] = 12`), увеличение `j` — на два столбца вправо\n",
    "(`strides[1] = 2`). Далее: увеличение `k` смещает на одну строку (`strides[2] = 6`), а увеличение `l` — на один\n",
    "столбец (`strides[3] = 1`).\n",
    "\n",
    "Создадим такое представление с помощью `np.lib.stride_tricks.as_strided()`. Эта функция задаёт новую форму и\n",
    "страйды **на тех же данных** (без копирования), поэтому очень эффективна — но требует осторожности,\n",
    "чтобы не выйти за границы исходного массива."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eafcce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.  1.]\n",
      "   [ 6.  7.]]\n",
      "\n",
      "  [[ 2.  3.]\n",
      "   [ 8.  9.]]\n",
      "\n",
      "  [[ 4.  5.]\n",
      "   [10. 11.]]]\n",
      "\n",
      "\n",
      " [[[12. 13.]\n",
      "   [18. 19.]]\n",
      "\n",
      "  [[14. 15.]\n",
      "   [20. 21.]]\n",
      "\n",
      "  [[16. 17.]\n",
      "   [22. 23.]]]\n",
      "\n",
      "\n",
      " [[[24. 25.]\n",
      "   [30. 31.]]\n",
      "\n",
      "  [[26. 27.]\n",
      "   [32. 33.]]\n",
      "\n",
      "  [[28. 29.]\n",
      "   [34. 35.]]]]\n"
     ]
    }
   ],
   "source": [
    "B = np.lib.stride_tricks.as_strided(A, shape=(3,3,2,2), strides=np.array((12,2,6,1))*4)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d590f9d",
   "metadata": {},
   "source": [
    "Парсить вывод многомерных массивов numpy не всегда интуитивно,\n",
    "но можно увидеть, что каждая подматрица 2x2 соответствует блоку исходной матрицы.\n",
    "Проверим, что реальная укладка в памяти не изменилась:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21a5f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28.\n",
      " 29. 30. 31. 32. 33. 34. 35.]\n"
     ]
    }
   ],
   "source": [
    "print(np.frombuffer(ctypes.string_at(B.ctypes.data, size=B.nbytes), B.dtype, B.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "213372de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 8, 24, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ccd26",
   "metadata": {},
   "source": [
    "Чтобы изменить порядок памяти таким образом, чтобы базовая матрица была непрерывной / компактной (что нам нужно для эффективного умножения матриц), мы можем использовать функцию `np.ascontinuugousarray()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02d505b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  6.  7.  2.  3.  8.  9.  4.  5. 10. 11. 12. 13. 18. 19. 14. 15. 20. 21. 16. 17. 22. 23. 24. 25. 30. 31. 26.\n",
      " 27. 32. 33. 28. 29. 34. 35.]\n"
     ]
    }
   ],
   "source": [
    "C = np.ascontiguousarray(B)\n",
    "print(np.frombuffer(ctypes.string_at(C.ctypes.data, size=C.nbytes), C.dtype, C.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc68c3",
   "metadata": {},
   "source": [
    "Как видно, массив `C` уложен в компактном порядке. Это можно подтвердить, посмотрев на `.strides`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cd024d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 16, 8, 4)\n"
     ]
    }
   ],
   "source": [
    "print(C.strides)\n",
    "# (3, 3, 2, 2) --> (12, 4, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d509e",
   "metadata": {},
   "source": [
    "## Свёртки через im2col\n",
    "\n",
    "Наконец, перейдём к «настоящему» способу реализации свёрток, который по скорости будет сопоставим с PyTorch.\n",
    "Идея: собрать всю вычислительную часть свёртки в **одно** матричное умножение,\n",
    "чтобы воспользоваться всеми оптимизациями матричного умножения.\n",
    "\n",
    "Ключевой приём — оператор `im2col`, который «разворачивает» 4D‑массив в вид,\n",
    "удобный для умножения. Посмотрим сначала на простой 2D‑пример, а потом перейдём к 4D.\n",
    "Возьмём тот же массив из начала раздела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a46fbe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17.]\n",
      " [18. 19. 20. 21. 22. 23.]\n",
      " [24. 25. 26. 27. 28. 29.]\n",
      " [30. 31. 32. 33. 34. 35.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(36, dtype=np.float32).reshape(6,6)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f38e4",
   "metadata": {},
   "source": [
    "И свёртку с фильтром 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8407b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]\n",
      " [6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "W = np.arange(9, dtype=np.float32).reshape(3,3)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f50479",
   "metadata": {},
   "source": [
    "Напомним, что свёртка умножает фильтр на каждый 3x3 блок изображения.\n",
    "Как извлечь все такие блоки? Сформируем массив размера $(H - K + 1) \\times (W - K + 1) \\times K \\times K$,\n",
    "содержащий все блоки 3x3, затем сплющим его в матрицу и умножим на фильтр\n",
    "Как создать такой массив без ручного копирования? Нам как раз поможет `as_strided()`.\n",
    "\n",
    "Если создать новое представление формы `(4,4,3,3)`, какие страйды задать?\n",
    "Первые два измерения будут иметь страйды 6 и 1 — как у обычного массива: шаг по первой оси — новая строка,\n",
    "шаг по второй — новый столбец. «Фишка» в том, что **третье и четвёртое** измерения **тоже** имеют страйды 6 и 1,\n",
    "потому что шаг по третьей оси также сдвигает нас на одну строку, а по четвёртой — на один столбец.\n",
    "Посмотрим на практике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51b2c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.  1.  2.]\n",
      "   [ 6.  7.  8.]\n",
      "   [12. 13. 14.]]\n",
      "\n",
      "  [[ 1.  2.  3.]\n",
      "   [ 7.  8.  9.]\n",
      "   [13. 14. 15.]]\n",
      "\n",
      "  [[ 2.  3.  4.]\n",
      "   [ 8.  9. 10.]\n",
      "   [14. 15. 16.]]\n",
      "\n",
      "  [[ 3.  4.  5.]\n",
      "   [ 9. 10. 11.]\n",
      "   [15. 16. 17.]]]\n",
      "\n",
      "\n",
      " [[[ 6.  7.  8.]\n",
      "   [12. 13. 14.]\n",
      "   [18. 19. 20.]]\n",
      "\n",
      "  [[ 7.  8.  9.]\n",
      "   [13. 14. 15.]\n",
      "   [19. 20. 21.]]\n",
      "\n",
      "  [[ 8.  9. 10.]\n",
      "   [14. 15. 16.]\n",
      "   [20. 21. 22.]]\n",
      "\n",
      "  [[ 9. 10. 11.]\n",
      "   [15. 16. 17.]\n",
      "   [21. 22. 23.]]]\n",
      "\n",
      "\n",
      " [[[12. 13. 14.]\n",
      "   [18. 19. 20.]\n",
      "   [24. 25. 26.]]\n",
      "\n",
      "  [[13. 14. 15.]\n",
      "   [19. 20. 21.]\n",
      "   [25. 26. 27.]]\n",
      "\n",
      "  [[14. 15. 16.]\n",
      "   [20. 21. 22.]\n",
      "   [26. 27. 28.]]\n",
      "\n",
      "  [[15. 16. 17.]\n",
      "   [21. 22. 23.]\n",
      "   [27. 28. 29.]]]\n",
      "\n",
      "\n",
      " [[[18. 19. 20.]\n",
      "   [24. 25. 26.]\n",
      "   [30. 31. 32.]]\n",
      "\n",
      "  [[19. 20. 21.]\n",
      "   [25. 26. 27.]\n",
      "   [31. 32. 33.]]\n",
      "\n",
      "  [[20. 21. 22.]\n",
      "   [26. 27. 28.]\n",
      "   [32. 33. 34.]]\n",
      "\n",
      "  [[21. 22. 23.]\n",
      "   [27. 28. 29.]\n",
      "   [33. 34. 35.]]]]\n"
     ]
    }
   ],
   "source": [
    "B = np.lib.stride_tricks.as_strided(A, shape=(4,4,3,3), strides=4*(np.array((6,1,6,1))))\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb39c25b",
   "metadata": {},
   "source": [
    "Это именно тот 4D‑массив, который нам нужен. Чтобы выполнить свёртку через одно матричное умножение,\n",
    " сплющим его в матрицу размера $(4\\cdot4) \\times (3\\cdot3)$, веса — в вектор длины 9\n",
    "(для многоканального случая веса станут матрицей), выполним матричное умножение и затем вернём форму 4x4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c7e8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28.\n",
      " 29. 30. 31. 32. 33. 34. 35.]\n"
     ]
    }
   ],
   "source": [
    "print(np.frombuffer(ctypes.string_at(B.ctypes.data, size=A.nbytes), B.dtype, A.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79daf789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4, 24, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfaa6a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = B.reshape(16,9)\n",
    "C.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e84ba6",
   "metadata": {},
   "source": [
    "Важно отметить, что под C выделяется память!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cf2437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ddd9026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 366.,  402.,  438.,  474.],\n",
       "       [ 582.,  618.,  654.,  690.],\n",
       "       [ 798.,  834.,  870.,  906.],\n",
       "       [1014., 1050., 1086., 1122.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B.reshape(16,9) @ W.reshape(9)).reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08c03a",
   "metadata": {},
   "source": [
    "### Важное замечание о расходе памяти\n",
    "\n",
    "Здесь есть **очень** важный момент про эффективность по памяти.\n",
    "Преобразование `W` в вектор «бесплатно» (новая память не выделяется), но преобразование `B` в 2D‑матрицу — **не бесплатное**.\n",
    "Страйдовое представление `B` использует ту же память, что и `A`, но когда мы превращаем `B` в 2D‑матрицу через reshape, то уже нельзя задать её страйдами без копии — приходится **материализовывать** всю матрицу.\n",
    "Это означает необходимость хранить полный im2col‑массив, что требует в $O(K^2)$ раз больше памяти\n",
    "по сравнению с исходным изображением, и это может быть дорого для больших ядер.\n",
    "\n",
    "Поэтому в современных реализациях часто **не** формируют полную im2col матрицу,\n",
    "а делают «ленивое» построение или специализируют матричное умножение под im2col представления.\n",
    "\n",
    "Все это довольно сложные темы, которые мы не будем рассматривать далее, потому что для наших целей будет достаточно просто выделить память под эту матрицу, а затем быстро освободить ее после выполнения свертки (помните, что мы, например, не выполняем backprop с помощью операции im2col)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91503a67",
   "metadata": {},
   "source": [
    "### im2col для многоканальных свёрток"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358af2ab",
   "metadata": {},
   "source": [
    "Как реализовать im2col для многоканальных, минибатч‑свёрток?\n",
    "Оказывается, процесс почти такой же. Вместо 4D‑массива $(H - K + 1) \\times (W - K + 1) \\times K \\times K$\n",
    "формируем 6D‑массив $N \\times (H - K + 1) \\times (W - K + 1) \\times K \\times K \\times C$\n",
    "(размерности батча и каналов не трогаем). И, после небольшого обдумывания, должно быть ясно, что можно применить тот же трюк и повторить страйды\n",
    "для высоты и ширины (измерения 1 и 2) в измерениях 3 и 4 (блоки $K \\times K$), а страйды батча и каналов оставить.\n",
    "Более того, можно просто взять существующие `.strides` входа `Z` и повторить их — без ручного подсчёта.\n",
    "\n",
    "Чтобы посчитать свёртку, сплющим im2col‑массив в матрицу\n",
    "$(N \\cdot (H - K + 1) \\cdot (W - K + 1)) \\times (K \\cdot K \\cdot C)$\n",
    "(помним: это неэффективно по памяти), веса — в матрицу\n",
    "$(K \\cdot K \\cdot C) \\times C_{out}$, выполним умножение и изменим форму к 4D‑выходу.\n",
    "Полная реализация приведена ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4a00e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_im2col(Z, weight):\n",
    "    N,H,W,C_in = Z.shape\n",
    "    K,_,_,C_out = weight.shape\n",
    "    Ns, Hs, Ws, Cs = Z.strides\n",
    "    \n",
    "    inner_dim = K * K * C_in\n",
    "    A = np.lib.stride_tricks.as_strided(Z, shape = (N, H-K+1, W-K+1, K, K, C_in),\n",
    "                                        strides = (Ns, Hs, Ws, Hs, Ws, Cs)).reshape(-1,inner_dim)\n",
    "    out = A @ weight.reshape(-1, C_out)\n",
    "    return out.reshape(N,H-K+1,W-K+1,C_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3955e0",
   "metadata": {},
   "source": [
    "Снова проверим совпадение с эталоном (или с предыдущими реализациями)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7df0666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6856471796294072e-12\n"
     ]
    }
   ],
   "source": [
    "Z = np.random.randn(100,32,32,8)\n",
    "W = np.random.randn(3,3,8,16)\n",
    "out = conv_reference(Z,W)\n",
    "out2 = conv_im2col(Z,W)\n",
    "print(np.linalg.norm(out - out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f888dd",
   "metadata": {},
   "source": [
    "На этом этапе скорость уже сопоставима с PyTorch: на моей машине отставание около 20-25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10bcfbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 ms, sys: 9.16 ms, total: 35.2 ms\n",
      "Wall time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out3 = conv_im2col(Z,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d446458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.7 ms, sys: 68.6 ms, total: 123 ms\n",
      "Wall time: 14.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out3 = conv_reference(Z,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351e341",
   "metadata": {},
   "source": [
    "## Итоговые замечания\n",
    "\n",
    "Надеюсь, это краткое введение помогло понять, что происходит «под капотом» реализаций свёрток,\n",
    "и насколько мощны манипуляции со страйдами: они позволяют выразить сложные операции без явных циклов\n",
    "по матрицам (хотя часть сложности перекладывается на `.reshape` и неявный `np.ascontiguousarray()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebc3f4",
   "metadata": {},
   "source": [
    "## ConvTranspose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d1989",
   "metadata": {},
   "source": [
    "Базовая иллюстрация работы транспонированной свёртки\n",
    "\n",
    "Ниже показано, что при свёртке y и w получим обратно x с точностью до константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fb789bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  0.,  2.,  0.],\n",
      "          [ 0., -1.,  0., -2.],\n",
      "          [ 3.,  0.,  4.,  0.],\n",
      "          [ 0., -3.,  0., -4.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[[1., 2.],\n",
    "                    [3., 4.]]]])          # (1, 1, 2, 2) — вход\n",
    "w = torch.tensor([[[[1., 0.],\n",
    "                    [0., -1.]]]])         # (1, 1, 2, 2) — ядро\n",
    "\n",
    "y = F.conv_transpose2d(x, w, stride=2, padding=0, output_padding=0)\n",
    "print(y)\n",
    "\n",
    "x_hat = F.conv2d(y, w, stride=2)\n",
    "torch.allclose(x_hat, x * w.norm()**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c24795",
   "metadata": {},
   "source": [
    "Реализация транспонированной свёртки через обычную\n",
    "\n",
    "Псевдокод:\n",
    "```\n",
    "x = dilate(x, stride)    # вставка нулей\n",
    "x = F.pad(x, (0, output_padding, 0, output_padding))\n",
    "w = weight.flip(-1,-2).permute(1,0,2,3)\n",
    "y = F.conv2d(x, w, padding=K-1-padding)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a7fc9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4305e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def dilate(x: torch.Tensor, stride: int):\n",
    "    if stride == 1:\n",
    "        return x\n",
    "    N, C, H, W = x.shape\n",
    "    H2, W2 = (H - 1) * stride + 1, (W - 1) * stride + 1\n",
    "    y = x.new_zeros(N, C, H2, W2)\n",
    "    y[:, :, ::stride, ::stride] = x\n",
    "    return y\n",
    "\n",
    "class ConvTransposeViaConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, stride=1, padding=0, output_padding=0, bias=True):\n",
    "        super().__init__()\n",
    "        self.stride, self.padding, self.output_padding = stride, padding, output_padding\n",
    "        w = torch.randn(in_ch, out_ch, k, k) * (2 / (in_ch * k * k))**0.5\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_ch)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = dilate(x, self.stride)\n",
    "        if self.output_padding:\n",
    "            x = F.pad(x, (0, self.output_padding, 0, self.output_padding))\n",
    "        w = self.weight.flip(-1, -2).permute(1, 0, 2, 3)\n",
    "        p = max(self.weight.shape[-1] - 1 - self.padding, 0)\n",
    "        return F.conv2d(x, w, bias=self.bias, stride=1, padding=p)\n",
    "\n",
    "# Проверка\n",
    "x = torch.randn(2, 3, 8, 8)\n",
    "w = torch.randn(3, 4, 3, 3)\n",
    "y_ref = F.conv_transpose2d(x, w, stride=2, padding=1, output_padding=1)\n",
    "layer = ConvTransposeViaConv(3, 4, 3, stride=2, padding=1, output_padding=1)\n",
    "layer.weight.data = w.clone()\n",
    "y = layer(x)\n",
    "\n",
    "print((y - y_ref).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe6e25",
   "metadata": {},
   "source": [
    "Вспомогательные вычисления для семинарских заметок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f615023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-27,  41],\n",
       "           [ 14,  12]]]]),\n",
       " tensor([[[[ -54,   55,  -67,  164],\n",
       "           [  28,  -43,  326, -157],\n",
       "           [  81, -108,   61, -142],\n",
       "           [ -42,  -22,  -16,  -24]]]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp = torch.tensor([[[[1, 2, -3, -2],\n",
    "                    [5, 1, 4, -4],\n",
    "                    [0, -2, 0, -5],\n",
    "                    [3, 0, -1, 1]]]])\n",
    "w_tmp = torch.tensor([[[[2, 1, 4],\n",
    "                    [0, 3, -5],\n",
    "                    [-3, 1, -2]]]])\n",
    "w_hat_tmp = torch.tensor([[[[2, 1, 4, 0, 0, 3, -5, 0, -3, 1, -2, 0, 0, 0, 0, 0],\n",
    "                           [0, 2, 1, 4, 0, 0, 3, -5, 0, -3, 1, -2, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 2, 1, 4, 0, 0, 3, -5, 0, -3, 1, -2, 0],\n",
    "                           [0, 0, 0, 0, 0, 2, 1, 4, 0, 0, 3, -5, 0, -3, 1, -2]]]])\n",
    "\n",
    "y_tmp = F.conv2d(x_tmp, w_tmp)\n",
    "z_tmp = F.conv_transpose2d(y_tmp, w_tmp, stride=1)\n",
    "\n",
    "y_tmp, z_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efce210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(w_hat_tmp @ x_tmp.flatten(), y_tmp.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc3e262f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(w_hat_tmp.transpose(-1, -2) @ y_tmp.flatten(), z_tmp.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd396f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
